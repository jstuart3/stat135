---
title: "Lab02 - HCMV"
author: "Jonathan Stuart"
date: "3/14/2018"
output: pdf_document
---


**Spacings and the Expoential and the Gamma**  
Gamma(2, 3, 4, $\lambda$) will probably be more accurate at finding clusters
than the exponential($\lambda$) because of dependence issues. Summing 2, 3, or 4
intervals will probably bring dependence; they'll be large or small together. And 
in this case, the dependence might be helpful. 

**Other Notes**  
The plots and figures used in the text are good ideas; it's ok to use the ideas
contained them, but they can't be explicityly reproduced for the report.

Definitely do some CI work; and inside the $I(\lambda)$ expression will be 
${\hat\lambda}$, which is normal when producing confidence intervals; we usually
estimate the parameter.

Picking the right size for the intervals is definitely a big part of the lab. He 
says that the Poisson is actually not applicable, or that for certain sizes it's
not applicable. He said it shouldn't be hard to find a size for which the Poisson
is not applicable. And when it is not, the $chi-square$ and other tests will 
indicate that. He also said that it would kind of be cheating to find just the 
right interval size and just the right parameter to make the Poisson work. His
advice was to write a function where the interval size would be an input, and have
that function run all the tests and give the results for that choice of interval 
size.  

He said that the Max Number of Hits section is "one way to do it," it's one tool,
but then so is the exponential/gamma discussion, and other things. Also, so is 
just the counts of occurences. There are many ways to make an arguement here, but
the idea is to make a convincing argument to our boss about how they should proceed
with the study. 

**Background**  
- Biologists conjecture that clusters of palindromes in HCMV may serve the same 
role as single long palindromes in Herpes simplex, i.e. indicators of origins
of replication.  
- HCMV DNA is 229, 354 base pairs long, with 296 total palindromes  
- Infection rates, vulnerable populations, pathology of the virus. Genomics and
other modern advances, application of knot theory to 3D stucture and molecular
dynamics of DNA.  

**Investigations**  
1. How do we find clusters of palindromes?  
2. How do we determine whether a cluster is a chance occurrence or an 
indication of a replication site?  
- Use the answers to these questions to advise a scientist about to start a 
search for an origin of replication  
- Pg. 82 - Discussion of interval size is key; does the interval with the largest
number of palindromes indicate a replication site? How do you know if your 
interval size is accurate or leads to indicative results? What happens if it's
too big? Too small?  

**Theory**  
- There are many properties of the homogeneous Poisson process that can be used
to check how well this reference model first the DNA data. So, we're essentially
asking of the Poisson process is an accurate distribtuion to apply to the data.  
- You can compare the observed counts to the expected number of counts per 
region. This leads to the $chi-square$ *Goodness-of-Fit* for this probability 
distribution (this is an hypothesis test). 
     - We could potentially seek to optimize the interval size through goodness 
     of fit testing. 
     - Another option would be to use a residual plot to measure goodness-of-fit.  
     - Another option is to compare the actual locations of palindromes with the
     expected locations of palindromes from a uniform distribution.
- Does the distance between successive hits follow the expoential distribution, 
as they should? Does the distance between, 2, 3, 4, etc hits follow a gamma
distribution, as they should?  
- We can use the distribution to find the projected maximum number of hits (this 
an hypothesis test.)
- We can have a discussion of using the method of moments and the method of 
maximum likelihood to get the estimate of $\lambda$, $\hat\lambda$.
- From the likelihood estimates we can compute the information, and use this to 
construct confidence intervals.
- We can conduct a final hypothesis test with a null hypothesis and an 
alternative hypothesis test, using a *z statistic*




**Extensions**
This is where you'll find the basis of the winning approach. It's moving a 
window of some size along the DNA, one base pair at a time, and finding the 
location of the window with the largest palindrome count. 

**Potential Plots (4)**  
Pg 81 - Random plots of 296 locations between 1 and 229, 354  
Pg 82 - Compare spacings between palindromes, sums of pairs of spacings, triplets
to what you would expect from a random scatter  

**Potential Tables(2)**  
-Pg 82 - Counts of palindromes in nonoverlapping regions compared to what you 
expect from a uniform random scatter. *Show* that the counts for short regions
will be more variable than the counts for larger regions.  
-Summarizing the Hypothesis Tests for each of the intervals


**To begin, pursue the point of view that structure in the data is indicated by 
departures from a univorm scatter of palindroms across the DNA.

Let's mount the necessary packages
```{r}
library('dplyr')
library('ggplot2')
library('MASS')
library('kableExtra')
```

Let's read in the data
```{r}
data <- read.csv("hcmv.csv")
```

Let's create 100 instances of random scatters of palindromes.
```{r}
set.seed(3)
random_palindromes <- matrix(NA , 296, 100)
for (i in 1:100) {
  random_palindromes[ , i] <- sort(sample(1:229354, 296, replace = FALSE))
}

```

functions to produce counts with variable interval size and data set
```{r}
#funtion to calculate the true length of the vector of palindrome counts
true_length <- function(x) {
  floor(229354/x)
}

#function that counts the number of palindromes and takes input of interval size
palindrome_count <- function(x) {
  counts <- 0
  iterator <- seq(from = 1, to = 229354, by = x)
  counts[1] <- nrow(filter(data, data[, 1] < x))
  for (i in 1:length(iterator)) {
    counts[i + 1] <- nrow(filter(data, data[, 1] > (iterator[i + 1] - iterator[1]) & 
                                  data[, 1] < iterator[i + 2] - iterator[1]))
  }
  counts <- counts[1:true_length(x)]
  return(counts)
}

#function that counts the number of palindromes and takes input of interval size
#and data set
super_palindrome_count <- function(data, x) {
  counts <- 0
  iterator <- seq(from = 1, to = 229354, by = x)
  counts[1] <- nrow(filter(data, data[, 1] < x))
  for (i in 1:length(iterator)) {
    counts[i + 1] <- nrow(filter(data, data[, 1] > (iterator[i + 1] - iterator[1]) & 
                                  data[, 1] < iterator[i + 2] - iterator[1]))
  }
  counts <- counts[1:true_length(x)]
  return(counts)
}
```

Goodness of Fit for Poisson with interval size 500
```{r}
#goodness of fit code

#counting number of palindromes in each interval
counts <- palindrome_count(500)
counts

#estimating lambda_hat as x_bar
lambda <- sum(counts) / length(counts)
lambda

#calculating the observed values (this doesn't account for intervals with zero palindromes)
count_table <- table(counts)
count_table

observed <- c(sum(count_table[1]), count_table[2], count_table[3], sum(count_table[4:7]))

observed <- unname(observed)
observed
expected <- 0
expected

#calculating expected values
expected[1] <- length(counts) * dpois(0, lambda)
expected[2] <- length(counts) * dpois(1, lambda)
expected[3] <- length(counts) * dpois(2, lambda)
expected[4] <- length(counts) * sum(dpois(3:8, lambda))

#calculating the chi-square test statistic
chi_test_statistic <- sum((observed - expected)^2 / expected)

#calculating the degrees of freedom
degrees_of_freedom <- length(expected) - 2

1 - dchisq(chi_test_statistic, degrees_of_freedom)

#calculating risiduals
  (observed - expected) / sqrt(expected)

#code for the maximum count
1 - (sum(dpois(0:7, lambda)))^(229354/500)

#confidence interval
#Fisher information for Poisson is 1/lambda
#lambda - (1.96 / sqrt(8/lambda))
lower <- lambda - (1.96 * sqrt(lambda/8))
upper <- lambda + (1.96 * sqrt(lambda/8))

upper-lower

```

Goodness of Fit for Poisson with interval size 2500
```{r}
#goodness of fit code

#counting number of palindromes in each interval
counts <- palindrome_count(2500)
counts

#estimating lambda_hat as x_bar
lambda <- sum(counts) / length(counts)
lambda

#calculating the observed values (this doesn't account for intervals with zero palindromes)
count_table <- table(counts)
count_table

observed <- c(count_table[1], count_table[2], count_table[3], count_table[4], count_table[5], count_table[6], sum(count_table[7:9]))

observed <- unname(observed)
observed
expected <- 0

#calculating expected values
expected[1] <- length(counts) * dpois(0, lambda)
expected[2] <- length(counts) * dpois(1, lambda)
expected[3] <- length(counts) * dpois(2, lambda)
expected[4] <- length(counts) * dpois(3, lambda)
expected[5] <- length(counts) * dpois(4, lambda)
expected[6] <- length(counts) * dpois(5, lambda)
expected[7] <- length(counts) * sum(dpois(6:13, lambda))


#calculating the chi-square test statistic
chi_test_statistic <- sum((observed - expected)^2 / expected)

#calculating the degrees of freedom
degrees_of_freedom <- length(expected) - 2

1 - dchisq(chi_test_statistic, degrees_of_freedom)

#calculating risiduals
  (observed - expected) / sqrt(expected)

#code for the maximum count
1 - (sum(dpois(0:12, lambda)))^(229354/2500)

#confidence interval
#Fisher information for Poisson is 1/lambda
lower <- lambda - (1.96 * sqrt(lambda/8))
upper <- lambda + (1.96 * sqrt(lambda/8))

upper-lower


```

Goodness of Fit for Poisson with interval size 4000
```{r}

  #counting number of palindromes in each interval
  counts <- super_palindrome_count(data, 4000)
  counts
  
  #estimating lambda_hat as x_bar
  lambda <- sum(counts) / length(counts)
  lambda
  
  #calculating the observed values (this doesn't account for intervals with zero palindromes)
  count_table <- table(counts)
  count_table
  
  observed <- c(sum(count_table[1:2]), count_table[3], count_table[4], 
                count_table[5], count_table[6], count_table[7], 
                count_table[8], sum(count_table[9:length(count_table)]))
  
  observed <- unname(observed)
  observed
  expected <- 0
  
  #calculating expected values
  expected[1] <- length(counts) * sum(dpois(0:2, lambda))
  expected[2] <- length(counts) * dpois(3, lambda)
  expected[3] <- length(counts) * dpois(4, lambda)
  expected[4] <- length(counts) * dpois(5, lambda)
  expected[5] <- length(counts) * dpois(6, lambda)
  expected[6] <- length(counts) * dpois(7, lambda)
  expected[7] <- length(counts) * dpois(8, lambda)
  expected[8] <- length(counts) * sum(dpois(9:14, lambda))
  
  #calculating the chi-square test statistic
  chi_test_statistic <- sum((observed - expected)^2 / expected)
  
  #calculating the degrees of freedom
  degrees_of_freedom <- length(expected) - 2
  
  1 - dchisq(chi_test_statistic, degrees_of_freedom)
  
  #calculating risiduals
  (observed - expected) / sqrt(expected)
  
  #code for the maximum count
1 - (sum(dpois(0:13, lambda)))^(floor(229354/4000))

#confidence interval
#Fisher information for Poisson is 1/lambda
lower <- lambda - (1.96 * sqrt(lambda/8))
upper <- lambda + (1.96 * sqrt(lambda/8))

upper-lower

```

Goodness of Fit for Poisson with interval size 7000
```{r}
#goodness of fit code - 7000

#counting number of palindromes in each interval
counts <- palindrome_count(7000)
counts

#estimating lambda_hat as x_bar
lambda <- sum(counts) / length(counts)
lambda

#calculating the observed values (this doesn't account for intervals with zero palindromes)
count_table <- table(counts)
count_table

observed <- c(sum(count_table[1:2]), count_table[3], count_table[4], count_table[5], count_table[6], count_table[7], count_table[8], count_table[9], count_table[10], count_table[11], sum(count_table[12:13]))

observed <- unname(observed)
observed
expected <- 0

#calculating expected values
expected[1] <- length(counts) * sum(dpois(0:4, lambda))
expected[2] <- length(counts) * dpois(5, lambda)
expected[3] <- length(counts) * dpois(6, lambda)
expected[4] <- length(counts) * dpois(7, lambda)
expected[5] <- length(counts) * dpois(8, lambda)
expected[6] <- length(counts) * dpois(9, lambda)
expected[7] <- length(counts) * dpois(10, lambda)
expected[8] <- length(counts) * dpois(11, lambda)
expected[9] <- length(counts) * dpois(12, lambda)
expected[10] <- length(counts) * dpois(13, lambda)
expected[11] <- length(counts) * sum(dpois(14:18, lambda))

#calculating the chi-square test statistic
chi_test_statistic <- sum((observed - expected)^2 / expected)

#calculating the degrees of freedom
degrees_of_freedom <- length(expected) - 2

1 - dchisq(chi_test_statistic, degrees_of_freedom)

#calculating risiduals
  (observed - expected) / sqrt(expected)

#code for the maximum count
1 - (sum(dpois(0:17, lambda)))^(229354/7000)

#confidence interval
#Fisher information for Poisson is 1/lambda
lower <- lambda - (1.96 * sqrt(lambda/8))
upper <- lambda + (1.96 * sqrt(lambda/8))

upper-lower


```

Code for lambda hat; discuss in the context of method of moments and maximum likelihood
```{r}
lambda_hat <- mean(counts)
lambda_hat
```

```{r}
#distance between hits; exponential;gamma
data
distances_exp <- 0
distances_gamma_2 <- 0
distances_gamma_3 <- 0

for (i in 1:295) {
  distances_exp[i] <- (data[i + 1, ] - data[i, ])
}

for (i in 1:294) {
  distances_gamma_2[i] <- (data[i + 2, ] - data[i, ])
}

for (i in 1:293) {
  distances_gamma_3[i] <- (data[i + 3, ] - data[i, ])
}

dat_distances_exp <- as.data.frame(distances_exp)
dat_distances_gamma_2 <- as.data.frame(distances_gamma_2)
dat_distances_gamma_3 <- as.data.frame(distances_gamma_3)

#x <- rgamma(100000, shape = 2, rate = 0.2)
#fit.params <- fitdistr(x, "gamma", lower = c(0, 0))

data =  data.frame(x=rexp(n = 100000, rate = .85))
m <- ggplot(data, aes(x=data$x))
m + geom_density()


ggplot(data = dat_distances_gamma_2) +
  geom_histogram(aes(x = dat_distances_gamma_2), bins = 20)

ggplot(data = dat_distances_gamma_3) +
  geom_histogram(aes(x = dat_distances_gamma_3), bins = 30)
```


```{r}
#exponential and gamma for distance between hits code
#z-test code
#sliding window code 
```


Background on the problem. HCVM family, volatility, desire to find replication sites. Replication
sites appear as clusters of palindromes.

These are the main questions we want to answer:e
1. How do we find clusters of palindromes?  
2. How do we determine whether a cluster is a chance occurrence or an 

Whether or not the poisson fits the data. Does it fit the data better than random scatter?

How do we know that size interval to use?

Conducted multiple hypothesis tests to check whether a poisson distr could be effectively 
fit to the data.

Yes, poisson is applicable, which allows us to see where we might want to focus for clustering.
We can look to the max counts data. 